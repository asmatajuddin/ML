{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Optimization in Machine Learning Models"
      ],
      "metadata": {
        "id": "lnTqxGVdHPMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is a Parameter in a Machine Learning Model?\n",
        "\n",
        "A model parameter is a configuration variable that is internal to the model and whose value can be estimated from the given data.\n",
        "\n",
        "They are required by the model when making predictions.\n",
        "Their values define the skill of the model on your problem.\n",
        "They are estimated or learned from data.\n",
        "They are often not set manually by the practitioner.\n",
        "They are often saved as part of the learned model.\n",
        "So your main take away from the above points should be parameters are crucial to machine learning algorithms. Also, they are the part of the model that is learned from historical training data. Let’s dig it a bit deeper. Think of the function parameters that you use while programming in general. You may pass a parameter to a function. In this case, a parameter is a function argument that could have one of a range of values. In machine learning, the specific model you are using is the function and requires parameters in order to make a prediction on new data. Whether a model has a fixed or variable number of parameters determines whether it may be referred to as “parametric” or “nonparametric“.\n",
        "\n",
        "Some examples of model parameters include:\n",
        "\n",
        "The weights in an artificial neural network.\n",
        "The support vectors in a support vector machine.\n",
        "The coefficients in a linear regression or logistic regression.\n",
        "What is a Hyperparameter in a Machine Learning Model?\n",
        "\n",
        "A model hyperparameter is a configuration that is external to the model and whose value cannot be estimated from data.\n",
        "\n",
        "They are often used in processes to help estimate model parameters.\n",
        "They are often specified by the practitioner.\n",
        "They can often be set using heuristics.\n",
        "They are often tuned for a given predictive modeling problem.\n",
        "You cannot know the best value for a model hyperparameter on a given problem. You may use rules of thumb, copy values used on other issues, or search for the best value by trial and error. When a machine learning algorithm is tuned for a specific problem then essentially you are tuning the hyperparameters of the model to discover the parameters of the model that result in the most skillful predictions.\n",
        "\n",
        "According to a very popular book called “Applied Predictive Modelling” - “Many models have important parameters which cannot be directly estimated from the data. For example, in the K-nearest neighbor classification model … This type of model parameter is referred to as a tuning parameter because there is no analytical formula available to calculate an appropriate value.”\n",
        "\n",
        "Model hyperparameters are often referred to as model parameters which can make things confusing. A good rule of thumb to overcome this confusion is as follows: “If you have to specify a model parameter manually, then it is probably a model hyperparameter. ” Some examples of model hyperparameters include:\n",
        "\n",
        "The learning rate for training a neural network.\n",
        "The C and sigma hyperparameters for support vector machines.\n",
        "The k in k-nearest neighbors.\n",
        "In the next section, you will discover the importance of the right set of hyperparameter values in a machine learning model.\n",
        "\n",
        "Importance of the Right Set of Hyperparameter Values in a Machine Learning Model\n",
        "\n",
        "The best way to think about hyperparameters is like the settings of an algorithm that can be adjusted to optimize performance, just as you might turn the knobs of an AM radio to get a clear signal. When creating a machine learning model, you'll be presented with design choices as to how to define your model architecture. Often, you don't immediately know what the optimal model architecture should be for a given model, and thus you'd like to be able to explore a range of possibilities. In a true machine learning fashion, you’ll ideally ask the machine to perform this exploration and select the optimal model architecture automatically.\n",
        "\n",
        "You will see in the case study section on how the right choice of hyperparameter values affect the performance of a machine learning model. In this context, choosing the right set of values is typically known as “Hyperparameter optimization” or “Hyperparameter tuning”.\n",
        "\n",
        "Two Simple Strategies to Optimize/Tune the Hyperparameters:\n",
        "\n",
        "Models can have many hyperparameters and finding the best combination of parameters can be treated as a search problem.\n",
        "\n",
        "Although there are many hyperparameter optimization/tuning algorithms now, this post discusses two simple strategies: 1. grid search and 2. Random Search.\n",
        "\n",
        "Grid searching of hyperparameters:\n",
        "\n",
        "Grid search is an approach to hyperparameter tuning that will methodically build and evaluate a model for each combination of algorithm parameters specified in a grid.\n",
        "\n",
        "Let’s consider the following example:\n",
        "\n",
        "Suppose, a machine learning model X takes hyperparameters a1, a2 and a3. In grid searching, you first define the range of values for each of the hyperparameters a1, a2 and a3. You can think of this as an array of values for each of the hyperparameters. Now the grid search technique will construct many versions of X with all the possible combinations of hyperparameter (a1, a2 and a3) values that you defined in the first place. This range of hyperparameter values is referred to as the grid.\n",
        "\n",
        "Suppose, you defined the grid as:\n",
        "a1 = [0,1,2,3,4,5]\n",
        "a2 = [10,20,30,40,5,60]\n",
        "a3 = [105,105,110,115,120,125]\n",
        "\n",
        "Note that, the array of values of that you are defining for the hyperparameters has to be legitimate in a sense that you cannot supply Floating type values to the array if the hyperparameter only takes Integer values.\n",
        "\n",
        "Now, grid search will begin its process of constructing several versions of X with the grid that you just defined.\n",
        "\n",
        "It will start with the combination of [0,10,105], and it will end with [5,60,125]. It will go through all the intermediate combinations between these two which makes grid search computationally very expensive.\n",
        "\n",
        "Let’s take a look at the other search technique Random search:\n",
        "\n",
        "Random searching of hyperparameters:\n",
        "\n",
        "The idea of random searching of hyperparameters was proposed by James Bergstra & Yoshua Bengio. You can check the original paper here.\n",
        "\n",
        "Random search differs from a grid search. In that you longer provide a discrete set of values to explore for each hyperparameter; rather, you provide a statistical distribution for each hyperparameter from which values may be randomly sampled.\n",
        "\n",
        "Before going any further, let’s understand what distribution and sampling mean:\n",
        "\n",
        "In Statistics, by distribution, it is essentially meant an arrangement of values of a variable showing their observed or theoretical frequency of occurrence.\n",
        "\n",
        "On the other hand, Sampling is a term used in statistics. It is the process of choosing a representative sample from a target population and collecting data from that sample in order to understand something about the population as a whole.\n",
        "\n",
        "Now let's again get back to the concept of random search.\n",
        "\n",
        "You’ll define a sampling distribution for each hyperparameter. You can also define how many iterations you’d like to build when searching for the optimal model. For each iteration, the hyperparameter values of the model will be set by sampling the defined distributions. One of the primary theoretical backings to motivate the use of a random search in place of grid search is the fact that for most cases, hyperparameters are not equally important. According to the original paper:\n",
        "\n",
        "“….for most datasets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different datasets. This phenomenon makes grid search a poor choice for configuring algorithms for new datasets.”\n",
        "\n",
        "In the following figure, we're searching over a hyperparameter space where the one hyperparameter has significantly more influence on optimizing the model score - the distributions shown on each axis represent the model's score. In each case, we're evaluating nine different models. The grid search strategy blatantly misses the optimal model and spends redundant time exploring the unimportant parameter. During this grid search, we isolated each hyperparameter and searched for the best possible value while holding all other hyperparameters constant. For cases where the hyperparameter being studied has little effect on the resulting model score, this results in wasted effort. Conversely, the random search has much improved exploratory power and can focus on finding the optimal value for the critical hyperparameter."
      ],
      "metadata": {
        "id": "Q0Ib3bItHSEa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case study in Python\n",
        "\n",
        "Hyperparameter tuning is a final step in the process of applied machine learning before presenting results.\n",
        "\n",
        "You will use the Pima Indian diabetes dataset. The dataset corresponds to a classification problem on which you need to make predictions on the basis of whether a person is to suffer diabetes given the 8 features in the dataset. You can find the complete description of the dataset here.\n",
        "\n",
        "There are a total of 768 observations in the dataset. Your first task is to load the dataset so that you can proceed. But before that let's import the dependencies, you are going to need."
      ],
      "metadata": {
        "id": "iJ1B9aMrHaj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependencies\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "metadata": {
        "id": "DXs3ceJLHgAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"diabetes.csv\") # Make sure the .csv file and the notebook are residing on the same directory otherwise supply an absolute path of the .csv file\n"
      ],
      "metadata": {
        "id": "TZMIKzD-HhMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()\n"
      ],
      "metadata": {
        "id": "FCWJz9YsHiwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()\n"
      ],
      "metadata": {
        "id": "KZQj6X7WHkee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(20)\n"
      ],
      "metadata": {
        "id": "SJEdfU87Hl8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\",header=None)\n",
        "print((data[[1,2,3,4,5]] == 0).sum())\n"
      ],
      "metadata": {
        "id": "SQ56yNJeHnU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mark zero values as missing or NaN\n",
        "data[[1,2,3,4,5]] = data[[1,2,3,4,5]].replace(0, np.NaN)\n",
        "# Count the number of NaN values in each column\n",
        "print(data.isnull().sum())\n"
      ],
      "metadata": {
        "id": "W432QZNjHojr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()\n"
      ],
      "metadata": {
        "id": "ds0QwsorHqLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with mean column values\n",
        "data.fillna(data.mean(), inplace=True)\n",
        "# Count the number of NaN values in each column\n",
        "print(data.isnull().sum())\n"
      ],
      "metadata": {
        "id": "K1s-VKuGHr0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into inputs and outputs\n",
        "values = data.values\n",
        "X = values[:,0:8]\n",
        "y = values[:,8]\n"
      ],
      "metadata": {
        "id": "J2u6XlKrHtQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate the LR model with random hyperparameters\n",
        "lr = LogisticRegression(penalty='l1',dual=False,max_iter=110)\n"
      ],
      "metadata": {
        "id": "ZSdVEKQ0HvMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass data to the LR model\n",
        "lr.fit(X,y)\n"
      ],
      "metadata": {
        "id": "_gNFvYhoHw4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, max_iter=110, multi_class='ovr', n_jobs=1,\n",
        "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
        "          verbose=0, warm_start=False)\n"
      ],
      "metadata": {
        "id": "eQ69S8-YHyUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr.score(X,y)\n"
      ],
      "metadata": {
        "id": "reEHBnwgH0PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You will need the following dependencies for applying Cross-validation and evaluating the cross-validated score\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n"
      ],
      "metadata": {
        "id": "_qCePaV3H140"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the k-fold cross-validator\n",
        "\n",
        "kfold = KFold(n_splits=3, random_state=7)\n"
      ],
      "metadata": {
        "id": "OYjG1BUgH5ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = cross_val_score(lr, X, y, cv=kfold, scoring='accuracy')\n",
        "print(result.mean())\n"
      ],
      "metadata": {
        "id": "2Ou_Das5H7E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n"
      ],
      "metadata": {
        "id": "nH-BrzxkH8nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dual=[True,False]\n",
        "max_iter=[100,110,120,130,140]\n",
        "param_grid = dict(dual=dual,max_iter=max_iter)\n"
      ],
      "metadata": {
        "id": "Dh7iQrKfIDAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "lr = LogisticRegression(penalty='l2')\n",
        "grid = GridSearchCV(estimator=lr, param_grid=param_grid, cv = 3, n_jobs=-1)\n",
        "\n",
        "start_time = time.time()\n",
        "grid_result = grid.fit(X, y)\n",
        "# Summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')\n"
      ],
      "metadata": {
        "id": "PTwdm9niIEV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dual=[True,False]\n",
        "max_iter=[100,110,120,130,140]\n",
        "C = [1.0,1.5,2.0,2.5]\n",
        "param_grid = dict(dual=dual,max_iter=max_iter,C=C)\n"
      ],
      "metadata": {
        "id": "6XsTlglBIGFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(penalty='l2')\n",
        "grid = GridSearchCV(estimator=lr, param_grid=param_grid, cv = 3, n_jobs=-1)\n",
        "\n",
        "start_time = time.time()\n",
        "grid_result = grid.fit(X, y)\n",
        "# Summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')\n"
      ],
      "metadata": {
        "id": "N7LXq2OxIJVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n"
      ],
      "metadata": {
        "id": "HO7hfzooIKq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random = RandomizedSearchCV(estimator=lr, param_distributions=param_grid, cv = 3, n_jobs=-1)\n",
        "\n",
        "start_time = time.time()\n",
        "random_result = random.fit(X, y)\n",
        "# Summarize results\n",
        "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
        "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')\n"
      ],
      "metadata": {
        "id": "hPvZkjpGIMnV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}